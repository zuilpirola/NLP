{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jMzNlnv53x-"
   },
   "source": [
    "# NLP2 - Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9uX04YI5yGx"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPr00E-_QT7M"
   },
   "source": [
    "Regular expressions (regex) are a powerful tool for searching, filtering, and manipulating text data, which is fundamental in natural language processing (NLP). Regex allows you to define flexible patterns that can match specific sequences of characters, making it ideal for tasks such as cleaning, preprocessing, or extracting structured information from unstructured text.\n",
    "\n",
    "Mastering regular expressions enables efficient handling of tasks, such as removing unwanted symbols, identifying relevant patterns (e.g., emails, dates, or phone numbers), and transforming raw text into a format suitable for further analysis. This becomes useful when preparing data for more advanced NLP methods you will learn about in this module, like tokenization, part-of-speech tagging, and named entity recognition, which relies on clean and well-structured text input.\n",
    "\n",
    "While regex is not the most scalable solution for large corpora or highly complex language tasks, it provides an accessible and effective way to automate repetitive text processing tasks in the early stages. Developing fluency with regex will serve as a foundation for understanding more sophisticated text analysis techniques, which we will explore later in the module.\n",
    "\n",
    "To work with regular expressions, we need to import a suitable Python library. The primary library used in Python for regular expressions is `re`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lmw_2_r6Cj_"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvX9RMIZlEyZ"
   },
   "source": [
    "We started working with them in the previous class, and we will continue today."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PpOhcHmzSB1Y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1727898646335,
     "user_tz": -60,
     "elapsed": 291,
     "user": {
      "displayName": "Zuil Filho",
      "userId": "14731231616780016906"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-10-07T13:10:07.395725Z",
     "start_time": "2025-10-07T13:10:07.390441Z"
    }
   },
   "source": [
    "# Import the re library\n",
    "import re\n",
    "\n",
    "#https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html\n",
    "#https://docs.python.org/3/library/re.html"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ws6D-Qs0NeVl"
   },
   "source": [
    "Apart from doing everything in code, you can use the editor:\n",
    "\n",
    "\n",
    "https://regex101.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__o6Wu_2P5Jg"
   },
   "source": [
    "## Basic examples\n",
    "\n",
    "1. Let's start with some examples. Imagine we want to extract especific instances of a target word in some input string, regardless of whether its first letter is uppercase or lowercase. What regular expression achieves this goal?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1727898648930,
     "user": {
      "displayName": "Zuil Filho",
      "userId": "14731231616780016906"
     },
     "user_tz": -60
    },
    "id": "dWcUnlbBP42i",
    "outputId": "2afcb969-93a8-415c-bbfd-e635b637ff1b",
    "ExecuteTime": {
     "end_time": "2025-10-07T18:26:18.530363Z",
     "start_time": "2025-10-07T18:26:18.527655Z"
    }
   },
   "source": [
    "#consider the string \"Amor √© bonito. Poucas pessoas sabem o que √© o amor.\"\n",
    "#extract the two occurrences of \"amor\" ou \"Amor\" using re.findall()\n",
    "\n",
    "a = \"Amor √© bonito. Poucas pessoas sabem o que √© o amor.\"\n",
    "\n",
    "ocor = re.findall(r\"[Aa]mor\",a)\n",
    "print(ocor)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amor', 'amor']\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpXXV4RoqGA1"
   },
   "source": [
    "2. What part of the regular expression is used to ensure it matches the target word starting either with upper or lowercase?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "E0fsAx4IqkQi",
    "ExecuteTime": {
     "end_time": "2025-10-07T13:15:54.496520Z",
     "start_time": "2025-10-07T13:15:54.494516Z"
    }
   },
   "source": [
    "#answer: [Aa]\n",
    "# explain this rule : \"[Aa]mor\"\n",
    "#[Aa] matches with range of characters, in this case A or a followed by mor\n",
    "#so [something] means match any one of the characters inside the brackets\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gYoEqxFXmKG"
   },
   "source": [
    "3. Now suppose our goal is to extract any numbers in an input string. What regular expression allows you to do that?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1727899003014,
     "user": {
      "displayName": "Zuil Filho",
      "userId": "14731231616780016906"
     },
     "user_tz": -60
    },
    "id": "XWcvHGJO6zSM",
    "outputId": "92113c61-235d-462f-ea4f-d813a0f15ca3",
    "ExecuteTime": {
     "end_time": "2025-10-07T18:30:02.475727Z",
     "start_time": "2025-10-07T18:30:02.473295Z"
    }
   },
   "source": [
    "# Extract numbers from a input string\n",
    "# Consider the example string\n",
    "# \"Moramos na Rua de Madrid, n√∫mero 14. Vamos nos mudar agora para a Pra√ßa de Londres, n√∫mero 20. Meu telem√≥vel √© 99987768076.\"\n",
    "\n",
    "a = \"Moramos na Rua de Madrid, n√∫mero 14. Vamos nos mudar agora para a Pra√ßa de Londres, n√∫mero 20. Meu telem√≥vel √© 99987768076.\"\n",
    "\n",
    "\n",
    "ocor = re.findall(\"[0-9]+\",a)\n",
    "print(ocor)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14', '20', '99987768076']\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH6MUkfIqDwF"
   },
   "source": [
    "4. What part of the regular expression ensures it matches all the digits in the different numbers? What alternatives can be used? What do each of them do exactly?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "U8LMQ4POrBid",
    "ExecuteTime": {
     "end_time": "2025-10-07T13:24:51.395842Z",
     "start_time": "2025-10-07T13:24:51.393641Z"
    }
   },
   "source": [
    "#answer\n",
    "# [0-9] means match any digit from 0 to 9\n",
    "# + means match one or more of the preceding element\n",
    "# so [0-9]+ means match one or more digits in a row\n",
    "# alternatives:\n",
    "# \\d means match any digit, equivalent to [0-9]\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A38BSLyfqibS"
   },
   "source": [
    "5 - What if we want to get words from a string?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1727899264480,
     "user": {
      "displayName": "Zuil Filho",
      "userId": "14731231616780016906"
     },
     "user_tz": -60
    },
    "id": "Ggm5OsmiW22h",
    "outputId": "82769678-7e45-42ab-cb10-bbd3021d1543",
    "ExecuteTime": {
     "end_time": "2025-10-07T13:25:04.668592Z",
     "start_time": "2025-10-07T13:25:04.665026Z"
    }
   },
   "source": [
    "#get words from a string\n",
    "#consider the string \"Moramos na Rua de Madri, n√∫mero 14. Vamos nos mudar agora para a Pra√ßa de Londres, n√∫mero 20. Meu telem√≥vel √© 99987768076.\"\n",
    "#how to fix √ß problem?\n",
    "\n",
    "a = \"Moramos na rua de Madrid, numero 14. Vamos mudar agora pra Pra√ßa de Londres numero 20. Meu telemovel 99987768076\"\n",
    "\n",
    "ocor = re.findall(\"[A-Za-z]+\",a)\n",
    "print(ocor)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Moramos', 'na', 'rua', 'de', 'Madrid', 'numero', 'Vamos', 'mudar', 'agora', 'pra', 'Pra', 'a', 'de', 'Londres', 'numero', 'Meu', 'telemovel']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGgLPf52rUty"
   },
   "source": [
    "6 - Based on the responses discussed above, what is the best approach for the regex pattern: allowing characters or blocking the ones we don't want?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fUmKYO9ArwrW",
    "ExecuteTime": {
     "end_time": "2025-10-07T18:39:35.065425Z",
     "start_time": "2025-10-07T18:39:35.062272Z"
    }
   },
   "source": [
    "#answer\n",
    "#returning only words\n",
    "ocor = re.findall(\"[A-Za-z√Ä-√ø]+\",a)\n",
    "print(ocor)\n",
    "\n",
    "#explain √Ä-√ø\n",
    "#√Ä-√ø means match any character from √Ä to √ø, which includes accented characters in Latin-1 Supplement Unicode block\n",
    "\n",
    "#using \\w but removing numbers\n",
    "ocor = re.findall(\"\\w+\",a)\n",
    "words = [word for word in ocor if not any(char.isdigit() for char in word)]\n",
    "print(words)\n",
    "\n",
    "#doing the same thing but without regex\n",
    "#first remove punctuation\n",
    "import string\n",
    "a_clean = a.translate(str.maketrans('', '', string.punctuation))\n",
    "#then split by space and get only words\n",
    "words = [word for word in a_clean.split() if word.isalpha()]\n",
    "print(words)\n",
    "\n",
    "#blocking everything that is not a letter\n",
    "ocor = re.findall(\"[^0-9.,;:!?\\\"'()\\-]+\",a)\n",
    "#and them split by space\n",
    "ocor = ' '.join(ocor).split()\n",
    "print(ocor)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Moramos', 'na', 'Rua', 'de', 'Madrid', 'n√∫mero', 'Vamos', 'nos', 'mudar', 'agora', 'para', 'a', 'Pra√ßa', 'de', 'Londres', 'n√∫mero', 'Meu', 'telem√≥vel', '√©']\n",
      "['Moramos', 'na', 'Rua', 'de', 'Madrid', 'n√∫mero', 'Vamos', 'nos', 'mudar', 'agora', 'para', 'a', 'Pra√ßa', 'de', 'Londres', 'n√∫mero', 'Meu', 'telem√≥vel', '√©']\n",
      "['Moramos', 'na', 'Rua', 'de', 'Madrid', 'n√∫mero', 'Vamos', 'nos', 'mudar', 'agora', 'para', 'a', 'Pra√ßa', 'de', 'Londres', 'n√∫mero', 'Meu', 'telem√≥vel', '√©']\n",
      "['Moramos', 'na', 'Rua', 'de', 'Madrid', 'n√∫mero', 'Vamos', 'nos', 'mudar', 'agora', 'para', 'a', 'Pra√ßa', 'de', 'Londres', 'n√∫mero', 'Meu', 'telem√≥vel', '√©']\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER2s89Oka9n4"
   },
   "source": [
    "7 - The idea is always to try to extract or locate substrings using patterns. For example, there are texts with separators (`,`). We can use these separators to assist in locate/extract substrings and texts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1727900667220,
     "user": {
      "displayName": "Zuil Filho",
      "userId": "14731231616780016906"
     },
     "user_tz": -60
    },
    "id": "QlTDlKhVbFcs",
    "outputId": "3f85e67e-65f0-400f-b4ad-54d3773eaadd",
    "ExecuteTime": {
     "end_time": "2025-10-07T18:44:28.325593Z",
     "start_time": "2025-10-07T18:44:28.321490Z"
    }
   },
   "source": [
    "#consider the string\n",
    "a = \"\"\"\n",
    "  Zuil,10\n",
    "  Amanda,50\n",
    "  Pedro,\n",
    "  Carlos,79\n",
    "  Jos√©,\n",
    "  Maria,20\n",
    "  ,60\n",
    "  \"\"\"\n",
    "\n",
    "#create a regex that returns only the lines that have the pattern \"Name,Age\" in tuple format. Ignore lines without age.\n",
    "\n",
    "ocor = re.findall(\"[A-Za-z√Ä-√ø]+,\\d+\",a)\n",
    "print(ocor)\n",
    "\n",
    "print([(x.split(\",\")[0],int(x.split(\",\")[1])) for x in ocor])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zuil,10', 'Amanda,50', 'Carlos,79', 'Maria,20']\n",
      "[('Zuil', 10), ('Amanda', 50), ('Carlos', 79), ('Maria', 20)]\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTjGZKvieMBQ"
   },
   "source": [
    "8 - Another case is to focus on locating or extracting occurrences of a word in both plural and singular forms."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fEA7HOUBePWP",
    "ExecuteTime": {
     "end_time": "2025-10-07T14:35:49.304864Z",
     "start_time": "2025-10-07T14:35:49.302496Z"
    }
   },
   "source": [
    "# consider the string \"Em Portugal h√° casas e casinhas. Cada casa pertence a uma pessoa. Os reis tinham castelos.\"\n",
    "\n",
    "a = \"Em Portugal h√° casas e casinhas. Cada casa pertence a uma pessoa. Os reis tinham castelos.\"\n",
    "\n",
    "#Use regex to write code that captures the word 'casa' and its plural derivation.\n"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDoo25Ztvkj8"
   },
   "source": [
    "9 - Therefore, the patterns we defined to extract substrings can even capture variations of words. Which characters do we have in regex that support the occurrence or non-occurrence of a particular pattern that follows?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SKMP3o-Ivizw",
    "ExecuteTime": {
     "end_time": "2025-10-07T14:46:45.244726Z",
     "start_time": "2025-10-07T14:46:45.242436Z"
    }
   },
   "source": [
    "#resolving plural and singular of casa\n",
    "ocor = re.findall(\"casas?\",a)\n",
    "print(ocor)\n",
    "#is possible to use same radical \"casa"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casas', 'casa']\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZgwI3HMhAX_"
   },
   "source": [
    "10 - Let's make things a bit more complicated. What if we wanted to get \"casa,\" \"casas\" and \"casinhas\" all the derivations of the word \"casa\"?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "d1WFoPD8hGlp",
    "ExecuteTime": {
     "end_time": "2025-10-07T18:55:56.157903Z",
     "start_time": "2025-10-07T18:55:56.155742Z"
    }
   },
   "source": [
    "a = \"em Portugal h√° casas e casinhas. Cada casa pertence a uma pessoa.\"\n",
    "#how about casinhas?\n",
    "ocor = re.findall(\"cas(?:a|inha)s?\",a)\n",
    "print(ocor)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casas', 'casinhas', 'casa']\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8fK8AXtyR3l"
   },
   "source": [
    "11 - When working with regex, we should always try to identify if there is a pattern and then construct the expression from there. An example is that numbers can have `.` or `,`. How can we obtain numbers containing both periods and commas from the example below?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FPXmEE0iyQ7-",
    "ExecuteTime": {
     "end_time": "2025-10-07T14:55:48.115509Z",
     "start_time": "2025-10-07T14:55:48.112713Z"
    }
   },
   "source": [
    "# consider the string\n",
    "a = \"\"\"Em 2023, a popula√ß√£o da cidade era de aproximadamente 1.234.567.\n",
    "Em compara√ß√£o, a popula√ß√£o em 2020 era de cerca de 1,2 milh√£o, destacando um crescimento significativo de cerca de 34,5%.\n",
    "  \"\"\"\n",
    "\n",
    "list_final = re.findall(\"\\d+[,.]*\\d+[,.]*\\d*\",a)\n",
    "print(list_final)\n",
    "\n",
    "list_final = re.findall(\"\\d+[,.]*\\d+[,.]*\\d*%?\",a)\n",
    "print(list_final)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023,', '1.234.567', '2020', '1,2', '34,5']\n",
      "['2023,', '1.234.567', '2020', '1,2', '34,5%']\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdfhHILmIXxZ"
   },
   "source": [
    "12 - When dealing with cases where we have more than one option, as proposed above, should we use `.` or `,` in regex?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9EbEEVr8I0Mp",
    "ExecuteTime": {
     "end_time": "2025-10-07T14:59:31.959799Z",
     "start_time": "2025-10-07T14:59:31.955690Z"
    }
   },
   "source": [
    "matches = re.findall(r'\\d+(?:[.,]\\d+)*', a)\n",
    "print(matches)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023', '1.234.567', '2020', '1,2', '34,5']\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92AAoOG9613f"
   },
   "source": [
    "13 - Let's use a bit of everything we've learned now. Extract all mentions of currencies contained in the text in a list format, also obtaining the currency symbol.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Gjsv3uIa80ZM",
    "ExecuteTime": {
     "end_time": "2025-10-07T15:04:45.231898Z",
     "start_time": "2025-10-07T15:04:45.228654Z"
    }
   },
   "source": [
    "# consider the text\n",
    "a = \"\"\"Ontem, fiz algumas compras online. Comprei um par de t√©nis por ‚Ç¨120,50 numa loja em Portugal.\n",
    "No mesmo site, havia uma oferta especial num casaco por ¬£85,99 (libras esterlinas), mas acabei por n√£o o comprar.\n",
    "Tamb√©m encontrei uma mochila que estava com um desconto de $75,20 (d√≥lares americanos), mas com os custos de envio, ficaria por ‚Ç¨90,00 ao todo.\n",
    "\n",
    "Na semana passada, quando viajei √† Su√≠√ßa, comprei um rel√≥gio por CHF 250,00 (francos su√≠√ßos), o que, ao c√¢mbio do dia, era aproximadamente ‚Ç¨230,00.\n",
    "Ainda troquei ‚Ç¨500,00 para ¬•60.000 (ienes japoneses) para a minha pr√≥xima viagem ao Jap√£o.\"\"\"\n",
    "\n",
    "list_final = re.findall(r\"[‚Ç¨¬£$¬•CHF]*\\s?\\d+[,.]\\d+\",a)\n",
    "print(list_final)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‚Ç¨120,50', '¬£85,99', '$75,20', '‚Ç¨90,00', 'CHF 250,00', '‚Ç¨230,00', '‚Ç¨500,00', '¬•60.000']\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGBZ-G9w5m5j"
   },
   "source": [
    "14 - What if we want to remove links from a text? Use `re.sub()`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QBIHorcj5WlT",
    "ExecuteTime": {
     "end_time": "2025-10-07T19:15:59.463282Z",
     "start_time": "2025-10-07T19:15:59.460323Z"
    }
   },
   "source": [
    "a = \"\"\"Hoje eu li alguns artigos interessantes na internet. Um deles foi sobre a import√¢ncia da sustentabilidade, que voc√™ pode encontrar www.link.com.\n",
    "Tamb√©m vi um v√≠deo no YouTube que fala sobre mudan√ßas clim√°ticas: video.pt.\n",
    "Al√©m disso, encontrei um blog que aborda tecnologia e inova√ß√£o, que voc√™ pode conferir em https://www.tecnologia-inovacao.com. Por √∫ltimo, um site de receitas que achei bem legal: http://www.receitasdeliciosas.com.\"\"\"\n",
    "\n",
    "print(a)\n",
    "print()\n",
    "pattern = r'https?://\\S+|www\\.\\S+|\\S+\\.(?:com|org|net|pt)'\n",
    "clean_text = re.sub(pattern, '', a)\n",
    "print(clean_text)\n",
    "\n",
    "#remove all links from string a"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoje eu li alguns artigos interessantes na internet. Um deles foi sobre a import√¢ncia da sustentabilidade, que voc√™ pode encontrar www.link.com.\n",
      "Tamb√©m vi um v√≠deo no YouTube que fala sobre mudan√ßas clim√°ticas: video.pt.\n",
      "Al√©m disso, encontrei um blog que aborda tecnologia e inova√ß√£o, que voc√™ pode conferir em https://www.tecnologia-inovacao.com. Por √∫ltimo, um site de receitas que achei bem legal: http://www.receitasdeliciosas.com.\n",
      "\n",
      "Hoje eu li alguns artigos interessantes na internet. Um deles foi sobre a import√¢ncia da sustentabilidade, que voc√™ pode encontrar \n",
      "Tamb√©m vi um v√≠deo no YouTube que fala sobre mudan√ßas clim√°ticas: .\n",
      "Al√©m disso, encontrei um blog que aborda tecnologia e inova√ß√£o, que voc√™ pode conferir em  Por √∫ltimo, um site de receitas que achei bem legal: \n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEoGc-MhO41m"
   },
   "source": [
    "15 - If we are analyzing an online conversation, we may need to extract the emojis. How would we do that?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7ds7nK_kO8Nf",
    "ExecuteTime": {
     "end_time": "2025-10-07T19:24:26.239312Z",
     "start_time": "2025-10-07T19:24:26.234168Z"
    }
   },
   "source": [
    "#consider the chat conversation\n",
    "text = \"\"\"\n",
    "Ana: Ei, Jo√£o! Como voc√™ est√°? üòä\n",
    "Jo√£o: Oi, Ana! T√¥ bem, e voc√™? Como foi o fim de semana? üòÑ\n",
    "Ana: Foi √≥timo! Fui √† praia com uns amigos üåä. E voc√™, fez algo legal?\n",
    "Jo√£o: Ah, que bom! Eu fiquei em casa, assisti uma s√©rie nova üé¨üçø. Tava precisando relaxar.\n",
    "Ana: Ah, √†s vezes √© bom ficar em casa tamb√©m, n√©? Qual s√©rie voc√™ viu? üì∫\n",
    "Jo√£o: Chama Mundos Paralelos, √© de fic√ß√£o cient√≠fica. Muito boa! üëΩ‚ú®\n",
    "Ana: Que massa! Eu adoro s√©ries assim! Vou anotar pra assistir depois. üòç\n",
    "Jo√£o: Faz isso! Acho que voc√™ vai curtir. E qual o plano pra essa semana?\n",
    "Ana: Ah, t√¥ cheia de trabalho üò©, mas no fim de semana vou dar uma escapadinha pra uma trilha ü•æüå≤.\n",
    "Jo√£o: Trilha √© sempre uma boa! Boa sorte com o trabalho e aproveita o fim de semana! üí™üòä\n",
    "Ana: Valeu! E vamos marcar algo tamb√©m, hein? üéâ\n",
    "Jo√£o: Com certeza! A gente combina direitinho. At√© mais, Ana! üëã\n",
    "Ana: At√©, Jo√£o! üëãüòä\"\"\"\n",
    "\n",
    "#use re.findall to find all emojis\n",
    "# Regex para emojis\n",
    "emoji_pattern = re.compile(\n",
    "    \"[\"\n",
    "    \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # S√≠mbolos e pictogramas\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # Transportes e mapas\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # Bandeiras\n",
    "    \"\\U00002700-\\U000027BF\"  # S√≠mbolos diversos\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Suplemento de s√≠mbolos e pictogramas\n",
    "    \"\\U00002600-\\U000026FF\"  # S√≠mbolos diversos\n",
    "    \"\\U00002B00-\\U00002BFF\"  # S√≠mbolos adicionais\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Suplemento de s√≠mbolos e pictogramas adicionais\n",
    "    \"]+\")\n",
    "\n",
    "emojis = emoji_pattern.findall(text)\n",
    "emojis = [char for char in text if emoji_pattern.match(char)]\n",
    "print(emojis)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['üòä', 'üòÑ', 'üåä', 'üé¨', 'üçø', 'üì∫', 'üëΩ', '‚ú®', 'üòç', 'üò©', 'ü•æ', 'üå≤', 'üí™', 'üòä', 'üéâ', 'üëã', 'üëã', 'üòä']\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JC6Q7_dZ7Bc"
   },
   "source": [
    "16 - For some studies, we may only be interested in longer words. How would we remove short words of 1 or 2 characters?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aUKP-PE1X2_D",
    "ExecuteTime": {
     "end_time": "2025-10-07T15:20:07.039840Z",
     "start_time": "2025-10-07T15:20:07.036942Z"
    }
   },
   "source": [
    "#consider\n",
    "\n",
    "a = \"√â estamos ai. J√° sabemos o que fazer.\"\n",
    "\n",
    "#Remove punctuation\n",
    "text_no_punct = re.sub(r'[^\\w\\s]', '', a)\n",
    "\n",
    "#Remove short words (1-2 characters)\n",
    "text_no_short = re.sub(r'\\b\\w{1,2}\\b', '', text_no_punct)\n",
    "\n",
    "#Remove extra spaces\n",
    "clean_text = re.sub(r'\\s{2,}', ' ', text_no_short).strip()\n",
    "\n",
    "print(clean_text)\n",
    "\n",
    "#make string clear from small words, extra spaces and punctuations"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estamos sabemos que fazer\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aILFPygge1X"
   },
   "source": [
    "17 - Final challenge:\n",
    "\n",
    "You have a dataset of chat conversations between users. Each message contains information such as timestamps, usernames, messages, and possibly URLs, emojis, and other unwanted elements. The goal is to clean the data and extract relevant information for analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "isdRaYFUgz7Y",
    "ExecuteTime": {
     "end_time": "2025-10-07T15:23:23.379707Z",
     "start_time": "2025-10-07T15:23:23.377508Z"
    }
   },
   "source": [
    "conversas = [\n",
    "    \"[10:15] @joao: Ol√°, como voc√™ est√°? Confira meu site http://meusite.com üòä\",\n",
    "    \"[10:16] @maria: Estou bem, obrigada! E voc√™? #feliz\",\n",
    "    \"[10:17] @joao: Vou bem tamb√©m! Veja isso: http://exemplo.com\",\n",
    "    \"[10:18] @maria: Que bom! Hahaha üòÇ\",\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra5knXgpg9JS"
   },
   "source": [
    "Objectives\n",
    "1. **Clean the messages** to remove:\n",
    "   - Timestamps (e.g., `[HH:MM]`)\n",
    "   - User mentions (e.g., `@username`)\n",
    "   - URLs (e.g., `http://example.com`)\n",
    "   - Emojis\n",
    "   - Hashtags (e.g., `#hashtag`)\n",
    "   - Unnecessary punctuation and extra spaces\n",
    "\n",
    "2. **Extract and count the frequency of remaining words** in the cleaned messages.\n",
    "\n",
    "3. **Create a summary with the total number of messages and the 10 most frequent words.**\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cpNM0C1Qg23b",
    "ExecuteTime": {
     "end_time": "2025-10-07T15:24:00.579918Z",
     "start_time": "2025-10-07T15:24:00.563977Z"
    }
   },
   "source": [
    "#1 - Clean the messages\n",
    "def clean_message(msg):\n",
    "    #Remove timestamps [HH:MM]\n",
    "    msg = re.sub(r'\\[\\d{2}:\\d{2}\\]', '', msg)\n",
    "\n",
    "    #Remove user mentions @username\n",
    "    msg = re.sub(r'@\\w+', '', msg)\n",
    "\n",
    "    #Remove URLs\n",
    "    msg = re.sub(r'https?://\\S+|www\\.\\S+|\\b\\S+\\.(?:com|org|net|pt)\\b', '', msg)\n",
    "\n",
    "    #Remove emojis (Unicode ranges)\n",
    "    msg = re.sub(\n",
    "        r'['\n",
    "        '\\U0001F600-\\U0001F64F'  # emoticons\n",
    "        '\\U0001F300-\\U0001F5FF'  # symbols & pictograms\n",
    "        '\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "        '\\U0001F1E0-\\U0001F1FF'  # flags\n",
    "        '\\U00002700-\\U000027BF'  # miscellaneous symbols\n",
    "        '\\U0001F900-\\U0001F9FF'  # supplemental symbols\n",
    "        '\\U00002600-\\U000026FF'\n",
    "        '\\U00002B00-\\U00002BFF'\n",
    "        '\\U0001FA70-\\U0001FAFF'\n",
    "        ']+', '', msg)\n",
    "\n",
    "    #Remove hashtags #hashtag\n",
    "    msg = re.sub(r'#\\w+', '', msg)\n",
    "\n",
    "    #Remove punctuation (keep letters, numbers, spaces)\n",
    "    msg = re.sub(r'[^\\w\\s]', '', msg, flags=re.UNICODE)\n",
    "\n",
    "    #Remove extra spaces\n",
    "    msg = re.sub(r'\\s{2,}', ' ', msg).strip()\n",
    "\n",
    "    return msg\n",
    "\n",
    "cleaned_conversas = [clean_message(msg) for msg in conversas]\n",
    "\n",
    "for msg in cleaned_conversas:\n",
    "    print(msg)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ol√° como voc√™ est√° Confira meu site\n",
      "Estou bem obrigada E voc√™\n",
      "Vou bem tamb√©m Veja isso\n",
      "Que bom Hahaha\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T15:24:15.636468Z",
     "start_time": "2025-10-07T15:24:15.633448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#2 - Extract and count the frequency of remaining words\n",
    "from collections import Counter\n",
    "all_words = ' '.join(cleaned_conversas).split()\n",
    "word_freq = Counter(all_words)\n",
    "print(word_freq)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'voc√™': 2, 'bem': 2, 'Ol√°': 1, 'como': 1, 'est√°': 1, 'Confira': 1, 'meu': 1, 'site': 1, 'Estou': 1, 'obrigada': 1, 'E': 1, 'Vou': 1, 'tamb√©m': 1, 'Veja': 1, 'isso': 1, 'Que': 1, 'bom': 1, 'Hahaha': 1})\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T15:24:41.313709Z",
     "start_time": "2025-10-07T15:24:41.311035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#3 - Create a summary with the total number of messages and the 10 most frequent words.\n",
    "total_messages = len(conversas)\n",
    "most_common_words = word_freq.most_common(10)\n",
    "print(f\"Total messages: {total_messages}\")\n",
    "print(\"10 most frequent words:\", most_common_words)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total messages: 4\n",
      "10 most frequent words: [('voc√™', 2), ('bem', 2), ('Ol√°', 1), ('como', 1), ('est√°', 1), ('Confira', 1), ('meu', 1), ('site', 1), ('Estou', 1), ('obrigada', 1)]\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
